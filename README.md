

locally_running_foundation_models_topic_outline

# ~platforms

### C-Transformers
- https://github.com/marella/ctransformers/blob/main/README.md

### tflite and on-edge
- https://github.com/huggingface/exporters
- https://huggingface.co/docs/optimum/exporters/tflite/usage_guides/export_a_model 
- https://github.com/huggingface/optimum-habana/blob/main/notebooks/AI_HW_Summit_2022.ipynb 


#### 6 From https://semaphoreci.com/blog/local-llm

### 1. Hugging Face and (hf)Transformers
- https://huggingface.co/

### 2. LangChain
-  MIT license 
- https://python.langchain.com/docs/get_started/introduction 
- https://github.com/langchain-ai/langchain 

### 3. Llama.cpp
-  MIT license 
- https://github.com/ggerganov/llama.cpp 

### 4. Llamafile
-  The Apache 2.0 License
- https://github.com/Mozilla-Ocho/llamafile 
- developed by Mozilla 

### 5. Ollama
https://ollama.ai/ 

### 6. GPT4ALL
-  MIT license 
- https://gpt4all.io/index.html 
- https://github.com/nomic-ai/gpt4all 

# Topics
- fine-tuner labs for jan
- local chat
- local rag
- local on the fly rag

#### non-generative model uses:
- classification
- distance
- embeddings
- concept analysis

#### ~RAG
- 


# Questions:


# ?
- chainlit https://docs.chainlit.io/get-started/overview 

### gpt4all 
- MIT license 
- https://gpt4all.io/index.html 
- https://github.com/nomic-ai/gpt4all 
